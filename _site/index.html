<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Scaling Open-Ended Reasoning to Predict the Future</title>
  <meta name="description"
    content="OpenForesight (dataset) and OpenForecaster (model): scaling open-ended reasoning for forecasting with retrieval and RL." />
  <meta name="color-scheme" content="light" />
  <link rel="stylesheet" href="/assets/styles.css" />
  <link rel="stylesheet" href="/assets/blog.css" />
  <link rel="icon" href="/assets/icons/favicon.svg" type="image/svg+xml" />
  <meta property="og:title" content="Scaling Open-Ended Reasoning to Predict the Future" />
  <meta property="og:description"
    content="OpenForesight (dataset) and OpenForecaster (model): scaling open-ended reasoning for forecasting with retrieval and RL." />
  <meta property="og:type" content="website" />

  <!-- MathJax for LaTeX equations -->
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    };
  </script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script>
</head>

<body>
  <header class="topbar">
    <a class="brand" href="/" aria-label="Home">OpenForecaster</a>
    <nav class="nav">
      <a href="#results">Results</a>
      <a href="#motivation">Motivation</a>
      <a href="#dataset">Dataset</a>
      <a href="#training">Training</a>
    </nav>
  </header>

  <main id="top">
    <!-- Hero Section with Resource Links -->
    <section class="blog-hero">
      <div class="container">
        <h1 class="title">Scaling Open-Ended Reasoning<br />To Predict the Future</h1>
        <p class="authors">
          Nikhil Chandak<sup>*</sup> · Shashwat Goel<sup>*</sup> · Ameya Prabhu<sup>†</sup> ·
          Moritz Hardt<sup>†</sup> · Jonas Geiping<sup>†</sup>
        </p>
        <p class="affiliations">
          Max Planck Institute for Intelligent Systems · ELLIS Institute Tübingen · Tübingen AI Center ·
          University of Tübingen
        </p>
        <p class="footnote"><sup>*</sup>Equal contribution · <sup>†</sup>Equal co-supervision</p>

        <div class="resource-links" id="resources">
          <a class="chip" data-link="arxiv" href="https://www.alphaxiv.org/abs/2512.25070" target="_blank"
            rel="noreferrer">
            <span class="icon" aria-hidden="true" data-icon="arxiv"></span>
            <span>Paper</span>
          </a>
          <a class="chip" data-link="code"
            href="https://github.com/OpenForecaster/scaling-forecasting-training/tree/main" target="_blank"
            rel="noreferrer">
            <span class="icon" aria-hidden="true" data-icon="github"></span>
            <span>Code</span>
          </a>
          <a class="chip" data-link="dataset" href="https://huggingface.co/datasets/nikhilchandak/OpenForesight"
            target="_blank" rel="noreferrer">
            <span class="icon" aria-hidden="true" data-icon="hf"></span>
            <span>Dataset</span>
          </a>
          <a class="chip" data-link="model" href="https://huggingface.co/nikhilchandak/OpenForecaster-8B"
            target="_blank" rel="noreferrer">
            <span class="icon" aria-hidden="true" data-icon="hf"></span>
            <span>Model</span>
          </a>
        </div>
      </div>
    </section>

    <!-- Blog Content -->
    <article class="blog-content">
      <div class="container">

        <!-- 
================================================================================
BLOG CONTENT STARTS HERE
Edit below this line to write your blog post.
You can use:
- Standard Markdown syntax
- LaTeX equations with $ for inline and $$ for display
- <details><summary>Title</summary>Content</details> for collapsible spoilers
- HTML when needed
================================================================================
-->

        <!-- # Motivation for LLM Forecasting -->

        <p>We built <strong>OpenForecaster</strong>, an 8B model trained to make predictions on open-ended forecasting
          questions. It is competitive with much larger proprietary models in held-out testing. We train it on our <a
            href="https://huggingface.co/datasets/nikhilchandak/OpenForesight">OpenForesight dataset</a> which has 52k
          forecasting questions created automatically from global news. This improves forecasting accuracy, calibration,
          and consistency of long-term predictions. We open-source all artefacts (including code), and describe our
          approach in the blog below.</p>

        <div class="figure-grid" id="results">
          <div class="figure-cell">
            <img src="assets/images/test_scatter_legend.png" alt="Legend"
              style="margin-bottom: 4px; border: none; box-shadow: none;" />
            <img src="assets/images/test_scatter.png" alt="Test set results" />
            <span class="caption"><strong>OpenForesight Test Set, May-August 2025 (302 Qs)</strong>: OpenForecaster 8B
              is competitive with 100B+ models on both Brier score and accuracy.</span>
          </div>
          <div class="figure-cell">
            <img src="assets/images/futurex_scatter.png" alt="FutureX results" />
            <span class="caption"><strong>FutureX July-August 2025 non-numeric (86 Qs)</strong>: OpenForecaster has a
              much higher accuracy than 100B+ models.</span>
          </div>
          <div class="figure-cell">
            <table>
              <thead>
                <tr>
                  <th>Consistency Check</th>
                  <th>Arbitrage (↓)</th>
                  <th>Frequentist (↓)</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>AND</td>
                  <td>−78%</td>
                  <td>−59%</td>
                </tr>
                <tr>
                  <td>Consequence</td>
                  <td>−66%</td>
                  <td>−31%</td>
                </tr>
                <tr>
                  <td>ExpEvidence</td>
                  <td>−64%</td>
                  <td>−31%</td>
                </tr>
                <tr>
                  <td>OR</td>
                  <td>−64%</td>
                  <td>−35%</td>
                </tr>
                <tr>
                  <td>Paraphrase</td>
                  <td>−50%</td>
                  <td>−27%</td>
                </tr>
                <tr>
                  <td>But</td>
                  <td>−47%</td>
                  <td>−17%</td>
                </tr>
                <tr>
                  <td>Negation</td>
                  <td>−32%</td>
                  <td>−11%</td>
                </tr>
                <tr>
                  <td><strong>Aggregated</strong></td>
                  <td><strong>−44%</strong></td>
                  <td><strong>−19%</strong></td>
                </tr>
              </tbody>
            </table>
            <span class="caption"><strong><a href="https://arxiv.org/abs/2412.18544" target="_blank">Consistency in
                  long-term predictions</a>.</strong> Our training reduces logical violations in predictions up to 2028,
              making forecasts more reliable. </span>
          </div>
          <div class="figure-cell">
            <img src="assets/images/ood_brier.png" alt="OOD calibration" />
            <span class="caption"><strong>Beyond forecasting</strong>: Calibration from forecasting training transfers
              to SimpleQA, MMLU-Pro, GPQA, which can be used to mitigate hallucinations.</span>
          </div>
        </div>

        <h1 id="motivation">Why we care about language model forecasting</h1>
        <p>Every day, we make decisions under uncertainty. Under the hood, such decisions often involve a forecasting
          problem.
          What gift will my friend
          like the most? How will this policy intervention impact the economy?
          Which experiment will lead to the most informative results for a research goal?</p>

        <p>At the outset, forecasting might seem subjective. Multiple options may be backed by reasonable arguments.
          Experts get it wrong all the time. This is by design–when making decisions with incomplete information, it is
          impossible to be perfect. There’s probably a ceiling to predictability, and we don’t know where it is.</p>

        <p>But crucially, in forecasting, we eventually learn the correct outcome. This
          provides the “verifiable” signal needed for evaluations and improvement. This is why forecasting has been a
          particularly successful application of Machine Learning–whether it be
          predicting prices, or the weather. </p>

        <p>Yet, traditional statistical and time-series models lack the expressivity
          to predict the kinds of questions we deal with in our day to day, which are expressible only in natural
          language, also called <strong>judgemental forecasting</strong>.</p>

        <p>Language models can change this. However, this requires qualitatively different capabilities than solving
          a fully specified math or code problem: seeking new information, aggregating unreliable sources, updating
          beliefs coherently and reporting appropriately hedged predictions. One could call it building a world model,
          but of events in society.</p>

        <p>So we ask:</p>
        <h1 id="how-to-train-language-model-forecasters">How to train language model forecasters?</h1>

        <p>Training data is the primary bottleneck for training AI forecasters. Making the model predict events that are
          truly in the future would be too slow a feedback loop: we’d have to wait for (at least) weeks before we get
          useful signal. Fortunately, LLMs know about the world only up to the date of their most recent training data,
          i.e. their “training cutoff”. All events afterwards are effectively “in the future” for the model. We can
          exploit this to create forecasting questions at scale, treating post-cutoff events as the “future” that models
          must predict.</p>

        <p>There are new interesting events happening around the world every day. Global news provides one way to
          capture them. In this work, we convert events reported in the news into open-ended forecasting questions. What
          do we mean by “open-ended”?</p>

        <p>1) The <em>questions</em> can be expressed in natural language, opening up the space of possible questions
          that can be forecasted.</p>

        <p>2) The <em>outcome space</em> is not a pre-defined set of options, unlike binary or multiple choice
          questions. The model has to come up with the possibilities on its own.</p>

        <p>For example, our automated pipeline creates forecasting questions like:</p>
        <ul>
          <li>“Who will be confirmed as the new prime minister of Ukraine on 17 July 2025?”</li>
          <li>“Which company will the US government buy a &gt;5% stake in by September 2025?”</li>
        </ul>

        <p>We will describe the automated question creation process later, but before that it is important to define how
          the forecasting model’s responses are scored.</p>

        <details>
          <summary>Why we don't use prediction markets, unlike prior work</summary>

          <p>Prior work on judgemental forecasting evaluations has predominantly depended on prediction markets to
            source forecasting questions. Prediction markets like <a href="https://polymarket.com/">Polymarket</a> and
            <a href="https://kalshi.com/">Kalshi</a> are platforms where people make probabilistic predictions on
            questions like “Will Zohran Momdani win the New York elections in 2025?”. However, there are a few drawbacks
            to relying on prediction markets for questions:
          </p>

          <ul>
            <li><strong>Volume</strong>: questions are written by humans, so it is hard to scale up the amount of
              training data.</li>
            <li><strong>Format</strong>: many questions are binary, i.e. have answers as ‘Yes’ or ‘No’. This leads to
              noisy rewards in training, where even wrong reasoning can lead to a correct guess and get reinforced.</li>
            <li><strong>Topic skew</strong>: platforms overrepresent certain areas, such as US Sports, Politics and
              Cryptocurrency. For example, 81% of questions in <a
                href="https://openreview.net/pdf?id=VpiHkMSPqI">ProphetArena</a>, a popular forecasting benchmark that
              sources questions from Kalshi, are about sports. If we train on these questions, the model is likely to
              learn sports-specific heuristics, and not general forecasting.</li>
          </ul>

        </details>

        <h2 id="scoring">Scoring</h2>

        <p>For each question, we ask the model for:</p>

        <ul>
          <li>a <strong>prediction</strong> (a short string), and</li>
          <li>a <strong>probability</strong> that its answer is correct.</li>
        </ul>

        <p>We can obviously calculate the accuracy of the predictions. But in forecasting, the reported probabilities
          are particularly important, as there is almost always some chance of being wrong. We expect reliable forecasts
          to be <em>calibrated</em>: the forecast probabilities match long-run observed frequencies.</p>

        <p>We want a scoring rule that promotes both accuracy and calibration:</p>

        <table>
          <thead>
            <tr>
              <th>Probability</th>
              <th style="text-align: right">Correctness</th>
              <th style="text-align: center">Score</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>0.9</td>
              <td style="text-align: right">no</td>
              <td style="text-align: center">big penalty</td>
            </tr>
            <tr>
              <td>0.1</td>
              <td style="text-align: right">no</td>
              <td style="text-align: center">small penalty</td>
            </tr>
            <tr>
              <td>0.3</td>
              <td style="text-align: right">yes</td>
              <td style="text-align: center">modest reward</td>
            </tr>
            <tr>
              <td>0.9</td>
              <td style="text-align: right">yes</td>
              <td style="text-align: center">near-max reward</td>
            </tr>
          </tbody>
        </table>

        <p>We adapt the <a href="https://statproofbook.github.io/D/bsr.html">multiclass brier score</a> for open-ended
          responses. The brier score provides a single number that incorporates both accuracy, and reliability of the
          reported probabilities, and is commonly used in judgemental forecasting.</p>

        <details>
          <summary>Formally</summary>

          <p>The model proposes one answer <code class="language-plaintext highlighter-rouge">y</code> and a scalar
            probability <code class="language-plaintext highlighter-rouge">q ∈ [0,1]</code> for “my answer is correct”.
            Let us say we grade the response $y$ to be correct if it’s semantically equivalent to the ground truth
            outcome $y^\star$, $c \;=\; \mathbb{1}[y \equiv y^\star]$, which is <code
              class="language-plaintext highlighter-rouge">1</code> when the response is deemed correct, and <code
              class="language-plaintext highlighter-rouge">0</code> otherwise. We will define how we check semantic
            equivalence in a bit.</p>

          <p>Then our brier score is:</p>

          <p>\(S'(q, y, y^\star) =
            \begin{cases}
            1-(q-1)^2, &amp; \text{if } c=1 \\
            -q^2, &amp; \text{if } c=0
            \end{cases}\)</p>
        </details>

        <p>Properties:</p>

        <ul>
          <li>If you output probability <code class="language-plaintext highlighter-rouge">0</code>, you always get a
            score of <code class="language-plaintext highlighter-rouge">0</code> (a neutral baseline), no matter what
            you predict. If you output probability <code class="language-plaintext highlighter-rouge">1</code>, then you
            get <code class="language-plaintext highlighter-rouge">+1</code> when correct and <code
              class="language-plaintext highlighter-rouge">-1</code> when wrong.</li>
          <li>Higher brier score is better. It reflects both <strong>more accurate predictions</strong> and
            <strong>appropriate uncertainty</strong>.
          </li>
          <li>Crucially, the brier score incentivizes <em>truthfulness</em>, i.e. it is optimal for the forecaster to
            report its true confidence.</li>
        </ul>

        <h3 id="how-do-we-grade-prediction-correctness">How do we grade prediction correctness?</h3>

        <p>With open-ended answers, we can’t just do exact string match. “Geoffrey Hinton” vs “Geoffrey Everest Hinton”
          should count as the same.</p>

        <p>So we use <strong>answer matching</strong>: another language model checks whether the predicted answer is
          <em>semantically equivalent</em> to the given ground truth.
        </p>

        <details>
          <summary>How reliable is answer matching with a language model?</summary>

          <p><a href="https://arxiv.org/abs/2507.02856">Our prior work</a> showed how now even small language models,
            like Qwen3-4B, can obtain high alignment with human grading on open-ended responses to questions from
            popular benchmarks like MMLU-Pro and GPQA-Diamond. Answer matching has been used across popular benchmarks
            released in 2025, such as Humanity’s Last Exam (HLE), OpenAI’s new FrontierScience, etc. In this work, we
            use:</p>

          <ul>
            <li>For evaluation we use <code class="language-plaintext highlighter-rouge">Llama-4-Scout</code> as the
              matcher, as it obtained inter-human level grading alignment in our earlier study.</li>
            <li>For training-time rewards we use <code class="language-plaintext highlighter-rouge">Qwen3-4B</code>
              (non-thinking) as the matcher, as it’s cheap, fast and accurate enough as a matcher. In the evaluations we
              did in this work, it agrees with Llama-4-Scout on around <strong>97%</strong> of graded responses, and our
              manual annotations found its judgements to be correct in at least <strong>95%</strong> cases.</li>
          </ul>

        </details>

        <h2 id="dataset">OpenForesight: News → Forecasting questions</h2>

        <p><img src="assets/images/qgen_pipeline.png"
            alt="Question-generation pipeline: generate candidates, validate/select, and rewrite to remove answer leakage." />
        </p>

        <p><em>Figure: Our automated recipe to create forecasting questions from news.</em></p>

        <p>We source news articles from <strong>CommonCrawl News (CCNews)</strong>: which provides monthly snapshots of
          articles across many news websites. For our training set, we obtain <strong>248k</strong> deduplicated
          English-language articles between June 2023 → April 2025, from 5 global news outlets: Forbes, CNN, Hindustan
          Times, Deutsche Welle, Irish Times</p>

        <p>We only train up to April 2025, as that’s the release date of the Qwen3 models we use. This retains a large
          window of events for held-out testing.</p>

        <p>1) <strong>Generate candidates.</strong> For each article, we use DeepSeek-v3 to propose up to three
          forecasting questions. This way, initially, we generate ~<strong>745k</strong> question candidates.</p>

        <p>2) <strong>Validate.</strong> A different model (Llama-4-Maverick) picks the best question according to our
          guidelines.</p>

        <p>3) <strong>Fix leakage.</strong> Even after the validation step, sometimes questions accidentally reveal the
          answer in the background or resolution text. We ask an LLM (LLama-4-Maverick) to identify potential leaking
          spans and only rewrite those parts of the questions. Finally, we filter questions which contain the answer
          string in the question, background, or resolution criteria.</p>

        <p>For this work, we only keep questions with non-numeric, short (1-3 word) string answers, resolving after
          January 2024. After filtering, we are left with <strong>52,183</strong> final samples (about
          <strong>7%</strong> of candidates). As a sanity check, when the source article is provided, <code
            class="language-plaintext highlighter-rouge">Qwen3-32B</code> can answer these questions at about
          <strong>95%</strong> accuracy, confirming the answers are grounded.
        </p>

        <p>We use the same recipe to create a 207 question validation set from The Guardian articles in July 2025. This
          helps us measure progress during development, and is what we report ablations on below. We create these
          questions using a stronger model (<code class="language-plaintext highlighter-rouge">o4-mini-high</code>) for
          higher quality.</p>

        <p>Similarly, for our final evaluation, we create a held-out test set of <strong>302</strong> high-quality
          questions (from 1,000 initial candidates) resolving between <strong>May–August 2025</strong>. These are drawn
          from five diverse global news sources not used in training: Al Jazeera, Time, The Independent, Fox News, and
          NDTV. We ensure high quality and zero leakage via strict quality control: filtering with search-enabled models
          (<code class="language-plaintext highlighter-rouge">grok-4.1-fast</code>), fixing resolution dates to the
          earliest reported occurrence, and manual review.</p>

        <p>Below, we show the benefit of filtering when training Qwen3-8B with GRPO and Brier score as reward, as
          measured on the validation set.
          <img src="assets/images/filtering_ablation.png" alt="Training with and without the filtering recipe." />
        </p>

        <p><em>Figure: Removing leakage and filtering for validity improves forecasting performance, and learning
            efficiency.</em></p>

        <p>Notice how:</p>
        <ul>
          <li>training <em>without</em> leakage removal can make the model worse. We attribute this to shortcut
            learning, as in this case we find 40% of samples contain the answer string.</li>
          <li>training with leakage removal, but no further filtering needs about <strong>3×</strong> more data/compute
            to get similar performance.</li>
          <li>the fully filtered set reaches better accuracy and Brier score in fewer iterations.</li>
        </ul>

        <details>
          <summary>Sample Generated Forecasting Question</summary>

          <p><strong>Question.</strong> Who will be confirmed as the new prime minister of Ukraine by 17 July 2025?</p>

          <p><strong>Background.</strong>
            Ukraine’s parliament is scheduled to vote to appoint a new prime minister.</p>

          <p><strong>Resolution Criteria.</strong></p>
          <ul>
            <li><strong>Source of Truth:</strong> Official announcement from the Verkhovna Rada (Ukraine’s parliament)
              confirming the appointment, via parliamentary records or government press release.</li>
            <li><strong>Resolution Date:</strong> 17 July 2025, the date on which the parliamentary vote occurs and
              results are published.</li>
            <li><strong>Accepted Answer Format:</strong> Full name of the individual exactly as given in the
              parliamentary announcement.</li>
          </ul>

          <p><strong>Answer Type.</strong> String (Name)</p>

          <p><strong>Ground-Truth Answer.</strong> Yulia Svyrydenko</p>

          <p><strong>Source.</strong> The Guardian (live blog): <a
              href="https://www.theguardian.com/world/live/2025/jul/17/ukraine-russia-war-patriot-nato-latest-europe-news-live-updates">Ukraine
              live updates — 17 July 2025</a></p>

        </details>

        <details>
          <summary>Example guidelines</summary>

          <ul>
            <li>fully supported by the source article,</li>
            <li>genuinely future-facing,</li>
            <li>resolvable to a clear, unambiguous answer by the deadline,</li>
            <li>written with explicit resolution criteria (source of truth + answer format),</li>
            <li>and worth asking (not trivial, not too vague).</li>
          </ul>

        </details>

        <h2 id="training">Training models for Forecasting with retrieval + RL</h2>

        <p>With data and metrics in place, the remaining question is: what does the training loop look like?</p>

        <p><strong>Retrieval.</strong> Forecasting greatly benefits from having access to recent information. So we use
          the Qwen3-Embedding-8B model to encode a corpus of ~<strong>1M</strong> de-duplicated CommonCrawl News
          (CCNews) articles across <strong>60</strong> sources in chunks of 512 tokens. We create query embeddings for
          each forecasting question, and retrieve the top 5 relevant chunks from articles up to one month before the
          resolution date. Our released dataset also has the final prompts with retrieved articles.</p>

        <p><img src="assets/images/retrieval_ablation.png"
            alt="Accuracy improves with offline retrieval across model sizes." /></p>

        <p><em>Figure: On our validation set, retrieval improves accuracy by about <strong>9–18%</strong> across model
            families and sizes.</em></p>

        <details>
          <summary>Why we use an *offline* news corpus (CCNews) and not web search</summary>

          <p><a href="https://arxiv.org/abs/2506.00723">Paleka et al. 2025</a> show how web search leaks future
            information in subtle ways:</p>

          <ul>
            <li>articles that were edited after publication, or</li>
            <li>ranking/indexing effects that “know” what became important later.</li>
          </ul>

          <p>So instead, we use CCNews, a static monthly snapshot of global news. This, along with only retrieving
            articles up to one month before the resolution date, are safety measures for ensuring we don’t leak future
            information to the model</p>
        </details>

        <p><strong>Reward Design.</strong> For GRPO training, the main design question is the reward. We find optimizing
          accuracy alone deteriorates Brier score. Optimizing Brier score improves both, but leads to lower accuracy
          than optimizing accuracy. We hypothesise this is because optimizing Brier score discourages exploration on
          hard questions. When the model assigns low probability, making a correct prediction (or not) does not change
          the reward (Brier score) much. Indeed, we find after Brier score only training, the model reports “Unknown”
          with near-zero confidence on 40% samples! Thus, we propose optimizing Accuracy + Brier score. This
          incentivizes making correct predictions even on hard questions with low confidence.</p>

        <p><img src="assets/images/reward_ablation.png"
            alt="Reward ablation: accuracy-only vs Brier-only vs Accuracy+Brier." /></p>

        <p><em>Figure: Rewarding Accuracy + Brier score leads to both higher accuracy and calibration, compared to using
            either alone.</em></p>

        <h3 id="the-final-training-recipe-what-we-actually-ran">The final training recipe (what we actually ran)</h3>

        <p>Putting it all together:</p>

        <ul>
          <li>Initial model: Qwen3 8B thinking model</li>
          <li>Retrieval: top-5 chunks using Qwen3-Embedding-8B (during training, we randomly vary between 0-5 chunks to
            make the model robust)</li>
          <li>Train on ~<strong>50k</strong> free-form questions from <code
              class="language-plaintext highlighter-rouge">OpenForesight</code>, and 2k resolved <strong>binary</strong>
            Metaculus questions (from 2024) to also handle that format.</li>
          <li>RL (GRPO) without normalization by standard deviation, rewarding: <strong>Accuracy + Brier</strong> for
            free-form, <strong>Brier</strong> for binary questions.</li>
        </ul>

        <p>This leads to our trained model <strong>OpenForecaster-8B</strong>, for which we already showed you the
          results <a href="#results">at the top</a>.</p>

        <h2 id="does-scaling-data-matter">Does scaling data matter?</h2>
        <p>To demonstrate this, we train Llama-3.1-8B-Instruct, as it has not already undergone RL post-training. Below,
          we vary the training data size, seeing continued improvements as the training data increases.</p>

        <div class="figure-grid">
          <div class="figure-cell">
            <img src="assets/images/scaling_brier.png" alt="Scaling Brier score" />
            <span class="caption">Scaling training data improves Brier score.</span>
          </div>
          <div class="figure-cell">
            <img src="assets/images/scaling_accuracy.png" alt="Scaling accuracy" />
            <span class="caption">Scaling training data improves accuracy.</span>
          </div>
        </div>

        <p>With our training, Llama-3.1-8B-Instruct surpasses Qwen3-235B, and DeepSeek v3, almost matching R1! And we
          don’t see any signs of saturation. It’s plausible we could scale our recipe further, using not only larger
          models and more news data, but also more diverse sources of events to forecast (AGI wen? Retrieve frontier lab
          vagueposts to find out.)</p>

        <h1 id="conclusion">Conclusion</h1>
        <p>There’s lots to explore in how to train language models for forecasting, and many exciting applications
          ranging from investing to policy! We think forecasting is a rich setting for studying LLM decision making,
          search agents, continual learning (from new knowledge, as the world evolves), world modelling and much more.
          We are actively exploring these directions, and if you’re interested in contributing, <a
            href="mailto:shashwatnow@gmail.com">reach out</a>. For more details, see our <a
            href="https://www.alphaxiv.org/abs/2512.25070">paper</a>. Do check out our released <a
            href="https://huggingface.co/datasets/nikhilchandak/OpenForesight">data</a>, <a
            href="https://github.com/OpenForecaster/scaling-forecasting-training/tree/main">code</a>, and <a
            href="https://huggingface.co/nikhilchandak/OpenForecaster-8B">model</a>, and let us know what you think!</p>

        <p><img src="assets/images/fig1.png"
            alt="Overview of our approach: generate open-ended forecasting questions from news, add retrieval, and train with GRPO." />
        </p>

        <p><em>Figure: Summary of our work. We propose an automated recipe to create forecasting questions from daily
            news. We release OpenForesight, our training data with 52k forecasting questions, and our full codebase. We
            use this to post-train Qwen3-8B, creating OpenForecaster 8B, which is competitive with much larger
            proprietary models on forecasting evaluations.</em></p>

        <!-- 
================================================================================
BLOG CONTENT ENDS HERE
================================================================================
-->

      </div>
    </article>

    <!-- Resources & Citation Section -->
    <section class="resources-section" id="citation">
      <div class="container">
        <h2>Citation</h2>
        <pre class="bibtex" aria-label="BibTeX citation">
@misc{chandak2025scalingopenendedreasoningpredict,
      title={Scaling Open-Ended Reasoning to Predict the Future}, 
      author={Nikhil Chandak and Shashwat Goel and Ameya Prabhu and Moritz Hardt and Jonas Geiping},
      year={2025},
      eprint={2512.25070},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2512.25070}, 
}
    </pre>
      </div>
    </section>

  </main>

  <script src="/assets/site.config.js"></script>
  <script src="/assets/main.js"></script>
</body>

</html>